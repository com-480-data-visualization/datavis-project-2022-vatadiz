{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_redundant_columns(df, excepted_columns=[]):\n",
    "    redundant_columns = {}\n",
    "    for col in df.columns:\n",
    "        if col not in excepted_columns:\n",
    "            val = df[col].unique()\n",
    "            if len(df[col].unique()) == 1:\n",
    "                redundant_columns[col] = val[0]\n",
    "    return redundant_columns\n",
    "\n",
    "def clean_redundant_columns(df : pd.DataFrame, dict_json, excepted_columns=[]):\n",
    "    rc = get_redundant_columns(df, excepted_columns=excepted_columns)\n",
    "    for column, value in rc.items():\n",
    "        dict_json[column] = value\n",
    "\n",
    "    df.drop(columns=rc.keys(), inplace=True)\n",
    "    \n",
    "# https://stackoverflow.com/questions/58408054/typeerror-object-of-type-bool-is-not-json-serializable\n",
    "class CustomJSONizer(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.bool_):\n",
    "            return super().encode(bool(obj))\n",
    "        elif isinstance(obj, np.int64):\n",
    "            return super().encode(int(obj))\n",
    "        elif not pd.notna(obj):\n",
    "            print(obj)\n",
    "            return super().encode(None)\n",
    "        else: \n",
    "            return super().default(obj)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "winter_folder = \"data/rlcs-202122/winter-major/\"\n",
    "main_filename = winter_folder + \"main_wmajor.csv\"\n",
    "players_m_filename = winter_folder + \"players_bo_wmajor.csv\"\n",
    "players_g_filename = winter_folder + \"players_g_wmajor.csv\"\n",
    "teams_m_filename = winter_folder + \"teams_bo_wmajor.csv\"\n",
    "teams_g_filename = winter_folder + \"teams_g_wmajor.csv\"\n",
    "\n",
    "\n",
    "\n",
    "main_df = pd.read_csv(main_filename).drop(columns=[\"Unnamed: 0\"])\n",
    "players_m_df = pd.read_csv(players_m_filename).drop(columns=[\"Unnamed: 0\"])\n",
    "players_g_df = pd.read_csv(players_g_filename).drop(columns=[\"Unnamed: 0\"])\n",
    "teams_m_df = pd.read_csv(teams_m_filename).drop(columns=[\"Unnamed: 0\"])\n",
    "teams_g_df = pd.read_csv(teams_g_filename).drop(columns=[\"Unnamed: 0\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>event</th>\n",
       "      <th>event_split</th>\n",
       "      <th>event_region</th>\n",
       "      <th>event_slug</th>\n",
       "      <th>event_start_date</th>\n",
       "      <th>event_end_date</th>\n",
       "      <th>event_tier</th>\n",
       "      <th>event_phase</th>\n",
       "      <th>prize_money</th>\n",
       "      <th>...</th>\n",
       "      <th>reverse_sweep_attempt</th>\n",
       "      <th>reverse_sweep</th>\n",
       "      <th>game_id</th>\n",
       "      <th>game_number</th>\n",
       "      <th>game_date</th>\n",
       "      <th>game_duration</th>\n",
       "      <th>map_id</th>\n",
       "      <th>map_name</th>\n",
       "      <th>overtime</th>\n",
       "      <th>ballchasing_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>614b6649f8090ec745286427</td>\n",
       "      <td>Major</td>\n",
       "      <td>Winter</td>\n",
       "      <td>World</td>\n",
       "      <td>https://octane.gg/events/6427-rlcs-2021-22-win...</td>\n",
       "      <td>2022-03-23 00:00:00+00:00</td>\n",
       "      <td>2022-03-27 22:30:00+00:00</td>\n",
       "      <td>S</td>\n",
       "      <td>Main Event</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>623c6335da9d7ca1c7bab21f</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DFH Stadium</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>614b6649f8090ec745286427</td>\n",
       "      <td>Major</td>\n",
       "      <td>Winter</td>\n",
       "      <td>World</td>\n",
       "      <td>https://octane.gg/events/6427-rlcs-2021-22-win...</td>\n",
       "      <td>2022-03-23 00:00:00+00:00</td>\n",
       "      <td>2022-03-27 22:30:00+00:00</td>\n",
       "      <td>S</td>\n",
       "      <td>Main Event</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>623fab38c437fde7e02d2c70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mannfield</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     event_id  event event_split event_region  \\\n",
       "73   614b6649f8090ec745286427  Major      Winter        World   \n",
       "129  614b6649f8090ec745286427  Major      Winter        World   \n",
       "\n",
       "                                            event_slug  \\\n",
       "73   https://octane.gg/events/6427-rlcs-2021-22-win...   \n",
       "129  https://octane.gg/events/6427-rlcs-2021-22-win...   \n",
       "\n",
       "              event_start_date             event_end_date event_tier  \\\n",
       "73   2022-03-23 00:00:00+00:00  2022-03-27 22:30:00+00:00          S   \n",
       "129  2022-03-23 00:00:00+00:00  2022-03-27 22:30:00+00:00          S   \n",
       "\n",
       "    event_phase  prize_money  ...  reverse_sweep_attempt reverse_sweep  \\\n",
       "73   Main Event     300000.0  ...                   True          True   \n",
       "129  Main Event     300000.0  ...                  False         False   \n",
       "\n",
       "                      game_id game_number  game_date  game_duration map_id  \\\n",
       "73   623c6335da9d7ca1c7bab21f         3.0        NaN          300.0    NaN   \n",
       "129  623fab38c437fde7e02d2c70         1.0        NaN          300.0    NaN   \n",
       "\n",
       "        map_name overtime ballchasing_id  \n",
       "73   DFH Stadium    False            NaN  \n",
       "129    Mannfield    False            NaN  \n",
       "\n",
       "[2 rows x 36 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Files with errors\n",
    "main_df[~main_df.game_date.notna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171\n",
      "342\n",
      "1026\n",
      "171\n",
      "342\n",
      "1026\n"
     ]
    }
   ],
   "source": [
    "print(len(main_df))\n",
    "print(len(teams_g_df))\n",
    "print(len(players_g_df))\n",
    "\n",
    "teams_g_columns_n = teams_g_df.drop(columns=[\"color\", \"team_id\", \"team_slug\", \"team_name\", \"team_region\", \"winner\"]).columns\n",
    "players_g_columns_n = players_g_df.drop(columns=[\"color\", \"team_id\", \"player_id\", \"player_tag\", \"camera_pitch\", \n",
    "                                           \"camera_distance\", \"camera_stiffness\", \"camera_swivel_speed\", \"camera_transition_speed\" , \"car_name\", \n",
    "                                           \"camera_fov\", \"camera_height\", \"steering_sensitivity\", \"car_id\", \"advanced_mvp\", \"team_region\", \"winner\",\n",
    "                                           \"platform_id\", \"platform\", ]).columns\n",
    "game_duration_df = main_df[[\"game_id\", \"game_duration\"]]\n",
    "teams_g_df = pd.merge(teams_g_df, game_duration_df, on='game_id',how='outer')\n",
    "players_g_df = pd.merge(players_g_df, game_duration_df, on='game_id',how='outer')\n",
    "\n",
    "for col in teams_g_columns_n:\n",
    "    if col not in [\"game_id\", \"game_duration\"]:\n",
    "        norm_col = col + \"_normalized\"\n",
    "        teams_g_df[norm_col] = teams_g_df[col] / teams_g_df.game_duration\n",
    "        teams_g_df[norm_col] = (teams_g_df[norm_col] - teams_g_df[norm_col].min())/(teams_g_df[norm_col].max() - teams_g_df[norm_col].min())\n",
    "\n",
    "for col in players_g_columns_n:\n",
    "    if col not in [\"game_id\", \"game_duration\"]:\n",
    "        norm_col = col + \"_normalized\"\n",
    "        players_g_df[norm_col] = players_g_df[col] / players_g_df.game_duration\n",
    "        players_g_df[norm_col] = (players_g_df[norm_col] - players_g_df[norm_col].min())/(players_g_df[norm_col].max() - players_g_df[norm_col].min())\n",
    "\n",
    "print(len(main_df))\n",
    "print(len(teams_g_df))\n",
    "print(len(players_g_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anony\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "winter_major_json = {}\n",
    "\n",
    "main_df_copy = main_df.copy()\n",
    "\n",
    "clean_redundant_columns(main_df_copy, winter_major_json)\n",
    "\n",
    "winter_major_json[\"players\"] = players_g_df[[\"player_tag\", \"player_id\", \"team_id\", \"team_region\"]].drop_duplicates().to_dict(orient=\"records\")\n",
    "winter_major_json[\"teams\"] = teams_g_df[[\"team_name\", \"team_id\", \"team_slug\", \"team_region\"]].drop_duplicates().to_dict(orient=\"records\")\n",
    "\n",
    "match_ids = main_df_copy.match_id.unique()\n",
    "matches = []\n",
    "games = []\n",
    "for m_id in match_ids:\n",
    "    match_json = {}\n",
    "    main_match_df = main_df_copy[main_df_copy.match_id == m_id]\n",
    "    clean_redundant_columns(main_match_df, match_json, ['reverse_sweep_attempt', 'reverse_sweep', 'game_duration', 'overtime'])\n",
    "    players_match = players_m_df[players_m_df.match_id == m_id].drop(columns=\"match_id\").to_dict(orient=\"records\")\n",
    "    \n",
    "    match_games_stats = []\n",
    "    game_without_problem_count = 0\n",
    "    game_ids = main_match_df.game_id.unique()\n",
    "    match_games = []\n",
    "    match_duration = 0.0\n",
    "    for g_id in game_ids:\n",
    "        game_json = main_match_df[main_match_df.game_id == g_id].to_dict(orient=\"records\")[0]\n",
    "        \n",
    "        if pd.notna(game_json[\"game_date\"]):\n",
    "            teams_game = teams_g_df[teams_g_df.game_id == g_id].drop(columns=\"game_id\").to_dict(orient=\"records\")\n",
    "            players_game = players_g_df[players_g_df.game_id == g_id].drop(columns=\"game_id\").to_dict(orient=\"records\")\n",
    "            team_count = 1\n",
    "            for tm in teams_game:\n",
    "                player_count = 1\n",
    "                for pm in players_game:\n",
    "                    if pm[\"team_id\"] == tm[\"team_id\"]:\n",
    "                        pn = f\"player{player_count}\"\n",
    "                        tm[pn] = pm.copy()\n",
    "                        tm[tm[pn][\"player_id\"]] = pn\n",
    "                        player_count += 1\n",
    "                tn = f\"team{team_count}\"\n",
    "                game_json[tn] = tm.copy()\n",
    "                game_json[game_json[tn][\"team_id\"]] = tn\n",
    "                team_count += 1\n",
    "            match_duration += game_json[\"game_duration\"]\n",
    "            game_without_problem_count += 1\n",
    "            game_json[\"technical_problems\"] = False\n",
    "            match_games_stats.append(game_json)\n",
    "        else:\n",
    "            for k in game_json:\n",
    "                if not pd.notna(game_json[k]):\n",
    "                    game_json[k] = None                    \n",
    "            game_json[\"technical_problems\"] = True\n",
    "        \n",
    "        match_games.append(game_json)\n",
    "        \n",
    "    # match_json[\"games\"] = match_games\n",
    "    teams_match = teams_m_df[teams_m_df.match_id == m_id].drop(columns=\"match_id\").to_dict(orient=\"records\")\n",
    "    team_count = 1\n",
    "    for tm in teams_match:\n",
    "        player_count = 1\n",
    "        tn = f\"team{team_count}\"\n",
    "        for pm in players_match:\n",
    "            if pm[\"team_id\"] == tm[\"team_id\"]:\n",
    "                pn = f\"player{player_count}\"\n",
    "                tm[pn] = pm.copy()\n",
    "                tm[tm[pn][\"player_id\"]] = pn\n",
    "                \n",
    "                p_stats = pd.DataFrame([stats_json[tn][pn] for stats_json in match_games_stats]).mean(numeric_only=True)\n",
    "                for k, v in p_stats.iteritems():\n",
    "                    if \"normalized\" in str(k):\n",
    "                        tm[pn][str(k)] = v\n",
    "                    \n",
    "                player_count += 1\n",
    "        match_json[tn] = tm.copy()\n",
    "        match_json[match_json[tn][\"team_id\"]] = tn\n",
    "        \n",
    "        t_stats = pd.DataFrame([stats_json[tn] for stats_json in match_games_stats]).mean(numeric_only=True)\n",
    "        for k, v in t_stats.iteritems():\n",
    "            if \"normalized\" in str(k):\n",
    "                match_json[tn][str(k)] = v\n",
    "        team_count += 1\n",
    "        \n",
    "    # print(match_games_stats_df.mean(numeric_only=True))\n",
    "    \n",
    "    games.extend(match_games)\n",
    "    match_json[\"games\"] = list(game_ids)\n",
    "    match_json[\"game_count\"] = len(games)\n",
    "    match_json[\"game_without_problem_count\"] = game_without_problem_count\n",
    "    match_json[\"match_duration\"] = match_duration\n",
    "    for tn in [\"team1\", \"team2\"]:\n",
    "        match_json[match_json[tn][\"team_id\"]] = tn\n",
    "    matches.append(match_json)\n",
    "    \n",
    "winter_major_json[\"matches\"] = dict((m[\"match_id\"], m) for m in matches)\n",
    "winter_major_json[\"games\"] = dict((g[\"game_id\"], g) for g in games)\n",
    "winter_major_json[\"players\"] = dict((p[\"player_id\"], p) for p in winter_major_json[\"players\"])\n",
    "winter_major_json[\"teams\"] = dict((t[\"team_id\"], t) for t in winter_major_json[\"teams\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WINTER MAJORS TEAM STATS\n",
    "\n",
    "for tid, t in winter_major_json[\"teams\"].items():\n",
    "    team_matches = []\n",
    "    team_matches_stats = []\n",
    "    team_games_stats = []\n",
    "    team_games = []\n",
    "    for mid, m in winter_major_json[\"matches\"].items():\n",
    "        team_match_stats = None\n",
    "        team_match_games_stats = None \n",
    "        if m[\"team1\"][\"team_id\"] == tid:\n",
    "            team_match_stats = m[\"team1\"]\n",
    "            team_match_games_stats = [winter_major_json[\"games\"][gid][\"team1\"] for gid in m[\"games\"] \n",
    "                                        if not winter_major_json[\"games\"][gid][\"technical_problems\"]]\n",
    "        elif m[\"team2\"][\"team_id\"] == tid:\n",
    "            team_match_stats = m[\"team2\"]\n",
    "            team_match_games_stats = [winter_major_json[\"games\"][gid][\"team2\"] for gid in m[\"games\"]\n",
    "                                      if not winter_major_json[\"games\"][gid][\"technical_problems\"]]\n",
    "        \n",
    "        if team_match_stats is not None:\n",
    "            team_matches_stats.append(team_match_stats)\n",
    "            team_matches.append(mid)\n",
    "            for gid in m[\"games\"]:\n",
    "                team_games.append(gid)\n",
    "            team_games_stats.extend(team_match_games_stats)\n",
    "    \n",
    "    team_match_stats_df = pd.DataFrame(team_matches_stats).drop(columns=[\"winner\",\"player1\", \"player2\", \"player3\", \"team_id\", \n",
    "                                                                         \"color\", \"team_slug\", \"team_name\", \"team_region\"])\n",
    "    t[\"match_stats_average\"] = team_match_stats_df.mean(numeric_only=True).to_dict()\n",
    "    \n",
    "    team_game_stats_df = pd.DataFrame(team_games_stats).drop(columns=[\"winner\",\"player1\", \"player2\", \"player3\", \"team_id\", \n",
    "                                                                      \"color\", \"team_slug\", \"team_name\", \"team_region\"])\n",
    "    t[\"game_stats_average\"] = team_game_stats_df.mean(numeric_only=True).to_dict()\n",
    "     \n",
    "    t[\"matches\"] = team_matches\n",
    "    t[\"games\"] = team_games\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_filename = winter_folder + \"winter_major_data_v3.json\"\n",
    "\n",
    "with open(out_filename, \"w\") as outfile:\n",
    "    json.dump(winter_major_json, outfile, cls=CustomJSONizer, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import compress_json\n",
    "import pickle\n",
    "\n",
    "with open(out_filename, \"r\") as f:\n",
    "    jf = json.load(f)\n",
    "    # compress_json.dump(jf, \"filepath.json.gz\")\n",
    "    with open(\"filepath.pkl\", \"wb\") as of:\n",
    "        pickle.dump(jf, of)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a745e65f00ba40f4710b3eb53765bd6a652c39d81dd3857a25c705af3598b4bd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
